{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011f5178",
   "metadata": {},
   "source": [
    "# Estudo de Caso 3 - Identificação de Anomalias em Texto com Pytorch\n",
    "\n",
    "O objetivo deste Jupyter Notebook é utilizar um modelo de machine learning com inteligência artificial para identificar frases que contém ou não fake news. Para isso, será utilizado liguagem Python e o Pytorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af563f",
   "metadata": {},
   "source": [
    "## 1. Instalação dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A versão da linguagem Python utilizada neste Jupyter Notebook é:  3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da linguagem Python\n",
    "from platform import python_version\n",
    "print('A versão da linguagem Python utilizada neste Jupyter Notebook é: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd0831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.0 requires torch==1.13.0, but you have torch 2.0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Instala versão do Pytorch\n",
    "!pip install -q torch==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d601949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala versão do Transformers\n",
    "!pip install -q transformers==4.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fcc6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga dos pacotes\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5afd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra somente mensagens de erro\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649fd0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Estudo de Caso 3 - Análise de Texto\n",
      "\n",
      "numpy       : 1.21.5\n",
      "transformers: 4.28.1\n",
      "torch       : 2.0.0\n",
      "sklearn     : 1.0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Estudo de Caso 3 - Análise de Texto\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cdfb9",
   "metadata": {},
   "source": [
    "## 2. Construção da Classe de Tokenização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9a54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para tokenização dos dados\n",
    "class TokenizaDados(Dataset):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    # Método para calcular o comprimento do texto (cada sentença)\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    # Método para obter um item tokenizado\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Obtém o índice do texto e do label\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Aplica a tokenização\n",
    "        inputs = self.tokenizer.encode_plus(text,\n",
    "                                           add_special_tokens = True,\n",
    "                                           max_length = self.max_length,\n",
    "                                           padding = 'max_length',\n",
    "                                           truncation = True,\n",
    "                                           return_tensors = 'pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f6a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf5c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73548cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb12793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f62e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f2e09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8007c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a8597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb641039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5a89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612e417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04d144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78539b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1471c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f6adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f7b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988205c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03143b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1476d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6ed0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a4bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2eb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc6d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fee9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a80fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab317160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e246130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b7826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a360db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
