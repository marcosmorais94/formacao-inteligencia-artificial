{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9d13b4",
   "metadata": {},
   "source": [
    "# Estudo de Caso 2 - Processo de Inicialização e Otimização\n",
    "\n",
    "Este Jupyter Notebook tem como objetivo a demonstração prática dos efeitos dos diferentes processos de inicialização e otimização para modelos com redes neurais. \n",
    "\n",
    "O processo de otimização em Deep Learning é o processo de encontrar os melhores pesos para a rede neural, de modo que ela possa realizar bem em tarefas específicas, como classificação ou regressão. Alguns exemplos são o SGD, Momentum e Adagrad.\n",
    "\n",
    "O processo de inicialização em Deep Learning é o processo de definir os valores iniciais dos pesos das camadas da rede neural antes do treinamento começar. Alguns exemplos são inicialização aleatória, inicialização com zero e com pequenos valores próximo a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ebf93",
   "metadata": {},
   "source": [
    "## 1. Carga e instalação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a02f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A versão da linguagem python neste Jupyter Notebook é:  3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da linguagem Python\n",
    "from platform import python_version\n",
    "print('A versão da linguagem python neste Jupyter Notebook é: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9377cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação versão do torch\n",
    "#!pip install -q torch==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990c800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação versão do Pytorch\n",
    "#!pip install -q torchvision==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb3c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga dos pacotes/funções\n",
    "\n",
    "# Pacote para trabalhar no SO\n",
    "import os\n",
    "\n",
    "# Pacotes de visualização e Processamento de dados\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "# Pacote Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Pacote Torchvison\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models\n",
    "\n",
    "# Relatório do ambiente de desenvolvimento\n",
    "import gc\n",
    "import types\n",
    "import pkg_resources\n",
    "import pytorch_lightning as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406a0ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Estudo de Caso 2 - Processos de Otimização/Inicialização\n",
      "\n",
      "torch            : 1.13.0\n",
      "numpy            : 1.21.5\n",
      "matplotlib       : 3.5.2\n",
      "torchvision      : 0.14.0\n",
      "pytorch_lightning: 1.8.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Estudo de Caso 2 - Processos de Otimização/Inicialização\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b239db4",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdb096",
   "metadata": {},
   "source": [
    "### 2.1 Criação das pastas no diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750471ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pasta_dados_originais = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39df445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_classes = ['cloudy', 'desert', 'green_area', 'water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a639f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para criar as pastas\n",
    "for i in range(len(nomes_classes)):\n",
    "    \n",
    "    # Extrai o nome de cada classe\n",
    "    class1 = '/' + nomes_classes[i]\n",
    "    \n",
    "    # Cria as pastas\n",
    "    os.makedirs('dados/treino/' + nomes_classes[i])\n",
    "    os.makedirs('dados/val/' + nomes_classes[i])\n",
    "    os.makedirs('dados/teste/' + nomes_classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276f1df",
   "metadata": {},
   "source": [
    "### 2.2 Input das imagens nas pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73622b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classe: cloudy\n",
      "Número Total de Imagens:  1500\n",
      "Imagens de Treino:  1050\n",
      "Imagens de Validação:  225\n",
      "Imagens de Teste:  225\n",
      "\n",
      "Classe: desert\n",
      "Número Total de Imagens:  1131\n",
      "Imagens de Treino:  791\n",
      "Imagens de Validação:  170\n",
      "Imagens de Teste:  170\n",
      "\n",
      "Classe: green_area\n",
      "Número Total de Imagens:  1500\n",
      "Imagens de Treino:  1050\n",
      "Imagens de Validação:  225\n",
      "Imagens de Teste:  225\n",
      "\n",
      "Classe: water\n",
      "Número Total de Imagens:  1500\n",
      "Imagens de Treino:  1050\n",
      "Imagens de Validação:  225\n",
      "Imagens de Teste:  225\n"
     ]
    }
   ],
   "source": [
    "# Loop\n",
    "for k in range(len(nomes_classes)):\n",
    "    \n",
    "    # Extrai um nome de classe\n",
    "    nome_classe = nomes_classes[k]\n",
    "    \n",
    "    # Define a fonte\n",
    "    src = pasta_dados_originais + \"/\" + nome_classe \n",
    "    \n",
    "    # Mostra qual classe estamos processando\n",
    "    print(\"\\nClasse:\", nomes_classes[k])\n",
    "    \n",
    "    # Lista o conteúdo da pasta\n",
    "    allFileNames = os.listdir(src)\n",
    "    \n",
    "    # \"Embaralha\" os dados\n",
    "    np.random.shuffle(allFileNames)\n",
    "    \n",
    "    # Divisão = 70% treino, 15% teste, 15% validação \n",
    "    train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                          [int(len(allFileNames)*0.7), int(len(allFileNames)*0.85)])\n",
    "\n",
    "\n",
    "    # Nome dos arquivos\n",
    "    train_FileNames = [src + '/' + name for name in train_FileNames.tolist()]\n",
    "    val_FileNames = [src + '/' + name for name in val_FileNames.tolist()]\n",
    "    test_FileNames = [src + '/' + name for name in test_FileNames.tolist()]\n",
    "\n",
    "    # Print\n",
    "    print('Número Total de Imagens: ', len(allFileNames))\n",
    "    print('Imagens de Treino: ', len(train_FileNames))\n",
    "    print('Imagens de Validação: ', len(val_FileNames))\n",
    "    print('Imagens de Teste: ', len(test_FileNames))\n",
    "    \n",
    "    # Copia as imagens\n",
    "    for name in train_FileNames:\n",
    "        shutil.copy(name, \"dados/treino/\" + nome_classe)\n",
    "    \n",
    "    for name in val_FileNames:\n",
    "        shutil.copy(name, \"dados/val/\" + nome_classe)\n",
    "        \n",
    "    for name in test_FileNames:\n",
    "        shutil.copy(name, \"dados/teste/\" + nome_classe)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c4b5e",
   "metadata": {},
   "source": [
    "### 2.3 Verificando o ambiente de desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfa285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Visão Geral do Ambiente---------------------------------------\n",
      "\n",
      "Device: cpu\n",
      "Pasta de Dados:  dados\n",
      "Versões dos Pacotes Requeridos:  [('matplotlib', '3.5.2'), ('numpy', '1.21.5'), ('torch', '1.13.0'), ('torchvision', '0.14.0')]\n",
      "Dispositivo Que Será Usado Para Treinar o Modelo:  cpu\n",
      "CUDA Está Disponível?  False\n",
      "Versão do PyTorch:  1.13.0+cpu\n",
      "Versão do Lightning:  1.8.3\n",
      "\n",
      "------------------Se NVIDIA-SMI não for encontrado, então CUDA não está disponível------------------\n",
      "\n",
      "\n",
      "Limpando a Memória da GPU (se disponível):  None\n",
      "\n",
      "------------------------------------------Fim da Checagem-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# Relatório completo\n",
    "\n",
    "# Verificando o dispositivo\n",
    "processing_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Verificando se GPU pode ser usada (isso depende da plataforma CUDA estar instalada)\n",
    "torch_aval = torch.cuda.is_available()\n",
    "\n",
    "# Labels para o relatório de verificação\n",
    "lable_1 = 'Visão Geral do Ambiente'\n",
    "lable_2 = 'Se NVIDIA-SMI não for encontrado, então CUDA não está disponível'\n",
    "lable_3 = 'Fim da Checagem'\n",
    "\n",
    "# Função para verificar o que está importado nesta sessão\n",
    "def get_imports():\n",
    "\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):            \n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        poorly_named_packages = {\"PIL\": \"Pillow\", \"sklearn\": \"scikit-learn\"}\n",
    "\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "# Imports nesta sessão\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# Loop para verificar os requerimentos\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "        \n",
    "# Pasta com os dados (quando necessário)\n",
    "pasta_dados = r'dados'\n",
    "\n",
    "print(f'{lable_1:-^100}')\n",
    "print()\n",
    "print(f\"Device:\", processing_device)\n",
    "print(f\"Pasta de Dados: \", pasta_dados)\n",
    "print(f\"Versões dos Pacotes Requeridos: \", requirements)\n",
    "print(f\"Dispositivo Que Será Usado Para Treinar o Modelo: \", processing_device)\n",
    "print(f\"CUDA Está Disponível? \", torch_aval)\n",
    "print(\"Versão do PyTorch: \", torch.__version__)\n",
    "print(\"Versão do Lightning: \", pl.__version__)\n",
    "print()\n",
    "print(f'{lable_2:-^100}\\n')\n",
    "!nvidia-smi\n",
    "gc.collect()\n",
    "print()\n",
    "print(f\"Limpando a Memória da GPU (se disponível): \", torch.cuda.empty_cache())\n",
    "print(f'\\n{lable_3:-^100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4e477",
   "metadata": {},
   "source": [
    "### 2.4 Funções auxiliares para input dos dados no dispositivo de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d61f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter o device\n",
    "# Se disponível usamos GPU, caso contrário usamos CPU.\n",
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a97d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para enviar um tensor para o device\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4871c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para enviar os dataloaders para o device\n",
    "class DeviceDataLoader():\n",
    "    \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "325cc4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o device\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ad5d2",
   "metadata": {},
   "source": [
    "## 3. Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edecac7a",
   "metadata": {},
   "source": [
    "### 3.1 Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c137dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo de normalização dos dados (médias e desvio padrão para cada canal de cor)\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac805b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as transformações dos dados\n",
    "transforms = transforms.Compose([transforms.RandomCrop(64, padding_mode = 'reflect'),\n",
    "                                 transforms.Resize(64),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(*stats, inplace = True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002a582",
   "metadata": {},
   "source": [
    "### 3.2 Carga dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7459ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "dados_treino = datasets.ImageFolder('dados/treino', transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33926893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de validação\n",
    "dados_valid = datasets.ImageFolder('dados/val', transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "479d5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de teste\n",
    "dados_teste = datasets.ImageFolder('dados/teste', transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e54b58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número Total de Imagens de Treino: 3941\n",
      "Número Total de Imagens de Validação: 845\n",
      "Número Total de Imagens de Teste: 845\n"
     ]
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "print(f\"Número Total de Imagens de Treino: {len(dados_treino)}\")\n",
    "print(f\"Número Total de Imagens de Validação: {len(dados_valid)}\")\n",
    "print(f\"Número Total de Imagens de Teste: {len(dados_teste)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6411d",
   "metadata": {},
   "source": [
    "### 3.3 Prepara os dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4adae435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros para os dataloaders\n",
    "batch_size = 8\n",
    "shuffle = True\n",
    "num_workers = 2\n",
    "pin_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5723de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader de treino\n",
    "data_loader_treino = DataLoader(dados_treino, \n",
    "                                batch_size, \n",
    "                                shuffle = shuffle, \n",
    "                                num_workers = num_workers, \n",
    "                                pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8418bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader de validação\n",
    "data_loader_valid = DataLoader(dados_valid, \n",
    "                               batch_size, \n",
    "                               num_workers = num_workers, \n",
    "                               pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "349ae59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader de teste\n",
    "data_loader_teste = DataLoader(dados_teste, \n",
    "                               batch_size * 2, \n",
    "                               num_workers = num_workers, \n",
    "                               pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54628d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para \"desnormalizar\" os dados\n",
    "def denormalize(images, means, stds):\n",
    "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
    "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
    "    return images * stds + means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c8e3d",
   "metadata": {},
   "source": [
    "## 4. Arquitetura do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86236eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a acurácia\n",
    "def accuracy(outputs, labels):\n",
    "    \n",
    "    # Extrai o maior valor dos outputs (classe com maior probabilidade)\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    \n",
    "    # Retorna a acurácia comparando as previsões com os valores reais\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09f39ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador Base\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Método de resert dos pesos (parâmetros)\n",
    "    def reset_parameters(self):\n",
    "        self.weight = torch.empty(3, 4)\n",
    "        nn.init.kaiming_uniform_(self.weight, mode = 'fan_in', nonlinearity = 'relu')\n",
    "    \n",
    "    # Método para o passo de treino\n",
    "    def training_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Método para o passo de validação\n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        \n",
    "        # Calcula a acurácia\n",
    "        acc = accuracy(out, labels)     \n",
    "        \n",
    "        return {'erro_valid': loss.detach(), 'acc_valid': acc}\n",
    "        \n",
    "    # Método para o passo de validação ao final de uma época\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['erro_valid'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['acc_valid'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'erro_valid': epoch_loss.item(), 'acc_valid': epoch_acc.item()}\n",
    "    \n",
    "    # Método para o fim de cada época\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, erro_treino: {:.4f}, erro_valid: {:.4f}, acc_valid: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['erro_treino'], result['erro_valid'], result['acc_valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b18257ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco de convolução\n",
    "def conv_block(in_channels, out_channels, pool = False):\n",
    "    \n",
    "    # Camadas\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace = True)]\n",
    "    \n",
    "    # Se pool = True, adiciona a camada de MaxPooling\n",
    "    if pool: \n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "        \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f063873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura ResNet\n",
    "class ResNet(ImageClassificationBase):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        \n",
    "        # Inicializa o construtor da classe mãe\n",
    "        super().__init__()\n",
    "        \n",
    "        # Conv1\n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        \n",
    "        # Conv2\n",
    "        self.conv2 = conv_block(64, 128, pool = True)\n",
    "        \n",
    "        # Sequência de convs\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        # Conv3\n",
    "        self.conv3 = conv_block(128, 256, pool = True)\n",
    "        \n",
    "        # Conv4\n",
    "        self.conv4 = conv_block(256, 512, pool = True)\n",
    "        \n",
    "         # Sequência de convs\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        # Camada de classificação\n",
    "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "    \n",
    "    # Método forward\n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "871b64d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveMaxPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria o objeto do modelo considerando 3 canais de cores nas imagens e 4 classes de saída\n",
    "modelo = to_device(ResNet(3, 4), device)\n",
    "\n",
    "# Visualiza o modelo\n",
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608af47",
   "metadata": {},
   "source": [
    "## 5. Carga dos Dados no Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ed06878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "data_loader_treino = DeviceDataLoader(data_loader_treino, device)\n",
    "\n",
    "# Dados de validação\n",
    "data_loader_valid = DeviceDataLoader(data_loader_valid, device)\n",
    "\n",
    "# Dados de teste\n",
    "data_loader_teste = DeviceDataLoader(data_loader_teste, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b763e3d",
   "metadata": {},
   "source": [
    "## 6. Funções para Loop de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f88d9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bad9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter a taxa de aprendizado\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0857df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treino\n",
    "def treina_modelo(epochs, \n",
    "                  max_lr, \n",
    "                  model, \n",
    "                  train_loader, \n",
    "                  val_loader, \n",
    "                  weight_decay = 0, \n",
    "                  grad_clip = None, \n",
    "                  opt_func = torch.optim.SGD):\n",
    "    \n",
    "    # Limpa o cache da GPU\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Lista para o histórico de treino\n",
    "    history = []\n",
    "    \n",
    "    # Define o otimizador com a função opt_func\n",
    "    if opt_func == torch.optim.Adam:\n",
    "        optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay)\n",
    "    elif opt_func == torch.optim.SGD:\n",
    "        optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay, momentum = 0.9)\n",
    "    elif opt_func == torch.optim.RMSprop:\n",
    "        optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay, eps = 1e-9)\n",
    "    \n",
    "    # Configura o agendador de taxa de aprendizado de um ciclo\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                                max_lr, \n",
    "                                                epochs = epochs, \n",
    "                                                steps_per_epoch = len(train_loader))\n",
    "    \n",
    "    # Loop de treino\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Coloca o modelo em modo de treino\n",
    "        model.train()\n",
    "        \n",
    "        # Listas de controle\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        \n",
    "        # Loop para extrair os batches\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            # Passo de treino\n",
    "            loss = model.training_step(batch)\n",
    "            \n",
    "            # Armazena o erro\n",
    "            train_losses.append(loss)\n",
    "            \n",
    "            # Backpropagation para calcular os gradientes\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping \n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            # Passo de otimização\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Zera os gradientes\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Registra e atualiza a taxa de aprendizado\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validação\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['erro_treino'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb608f9b",
   "metadata": {},
   "source": [
    "### 5.1 Definições de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3440a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos hiperparâmetros\n",
    "epochs = 5\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ad0da",
   "metadata": {},
   "source": [
    "### 5.2 Otimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278aff7",
   "metadata": {},
   "source": [
    "#### 5.2.1 ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34232080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "317e3c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00759, erro_treino: 0.9517, erro_valid: 1.3179, acc_valid: 0.7134\n",
      "Epoch [1], last_lr: 0.00950, erro_treino: 1.2679, erro_valid: 0.3811, acc_valid: 0.8375\n",
      "Epoch [2], last_lr: 0.00611, erro_treino: 0.7223, erro_valid: 0.4184, acc_valid: 0.8243\n",
      "Epoch [3], last_lr: 0.00188, erro_treino: 0.5394, erro_valid: 0.2738, acc_valid: 0.8943\n",
      "Epoch [4], last_lr: 0.00000, erro_treino: 0.4418, erro_valid: 0.2268, acc_valid: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cf9e179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'erro_valid': 0.24813513457775116, 'acc_valid': 0.9171807169914246}]\n"
     ]
    }
   ],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7030d1",
   "metadata": {},
   "source": [
    "#### 5.2.2 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46411286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22c2cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00759, erro_treino: 0.4452, erro_valid: 0.2574, acc_valid: 0.9120\n",
      "Epoch [1], last_lr: 0.00950, erro_treino: 0.4394, erro_valid: 0.2650, acc_valid: 0.8856\n",
      "Epoch [2], last_lr: 0.00611, erro_treino: 0.4254, erro_valid: 0.3389, acc_valid: 0.8642\n",
      "Epoch [3], last_lr: 0.00188, erro_treino: 0.4376, erro_valid: 0.2360, acc_valid: 0.9050\n",
      "Epoch [4], last_lr: 0.00000, erro_treino: 0.4037, erro_valid: 0.2392, acc_valid: 0.8967\n"
     ]
    }
   ],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e29a3cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'erro_valid': 0.27395811676979065, 'acc_valid': 0.8768141865730286}]\n"
     ]
    }
   ],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb37bdc",
   "metadata": {},
   "source": [
    "#### 5.2.3 RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2a9cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd11be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00759, erro_treino: 2.0377, erro_valid: 24.0316, acc_valid: 0.4224\n",
      "Epoch [1], last_lr: 0.00950, erro_treino: 5.4999, erro_valid: 2.4756, acc_valid: 0.4524\n",
      "Epoch [2], last_lr: 0.00611, erro_treino: 6.3445, erro_valid: 4.1171, acc_valid: 0.6191\n"
     ]
    }
   ],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19513c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f42fd2",
   "metadata": {},
   "source": [
    "## 6. Processos de Inicialização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f94bf8",
   "metadata": {},
   "source": [
    "### 6.1 Inicialização Glorot (Xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60815173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador Base\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Método de resert dos pesos (parâmetros)\n",
    "    def reset_parameters(self):\n",
    "        self.weight = torch.empty(3, 4)\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "    \n",
    "    # Método para o passo de treino\n",
    "    def training_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Método para o passo de validação\n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        \n",
    "        # Calcula a acurácia\n",
    "        acc = accuracy(out, labels)     \n",
    "        \n",
    "        return {'erro_valid': loss.detach(), 'acc_valid': acc}\n",
    "        \n",
    "    # Método para o passo de validação ao final de uma época\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['erro_valid'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['acc_valid'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'erro_valid': epoch_loss.item(), 'acc_valid': epoch_acc.item()}\n",
    "    \n",
    "    # Método para o fim de cada época\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, erro_treino: {:.4f}, erro_valid: {:.4f}, acc_valid: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['erro_treino'], result['erro_valid'], result['acc_valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do modelo considerando 3 canais de cores nas imagens e 4 classes de saída\n",
    "modelo = to_device(ResNet(3, 4), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d8ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2649cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650b7c2",
   "metadata": {},
   "source": [
    "### 6.3 Inicialização dos Pesos com Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4cec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador Base\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Método de resert dos pesos (parâmetros)\n",
    "    def reset_parameters(self):\n",
    "        self.weight = torch.empty(3, 4)\n",
    "        nn.init.zeros_(self.weight)\n",
    "    \n",
    "    # Método para o passo de treino\n",
    "    def training_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Método para o passo de validação\n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        \n",
    "        # Calcula a acurácia\n",
    "        acc = accuracy(out, labels)     \n",
    "        \n",
    "        return {'erro_valid': loss.detach(), 'acc_valid': acc}\n",
    "        \n",
    "    # Método para o passo de validação ao final de uma época\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['erro_valid'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['acc_valid'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'erro_valid': epoch_loss.item(), 'acc_valid': epoch_acc.item()}\n",
    "    \n",
    "    # Método para o fim de cada época\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, erro_treino: {:.4f}, erro_valid: {:.4f}, acc_valid: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['erro_treino'], result['erro_valid'], result['acc_valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do modelo considerando 3 canais de cores nas imagens e 4 classes de saída\n",
    "modelo = to_device(ResNet(3, 4), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
