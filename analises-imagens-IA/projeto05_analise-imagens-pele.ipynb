{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf74d55",
   "metadata": {},
   "source": [
    "# PROJETO 5 - ANÁLISE DE LESÕES NA PELE COM INTELIGÊNCIA ARTIFICIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d839076",
   "metadata": {},
   "source": [
    "Neste projeto será feito uma classificação multiclasses de diferentes tipos de lesões na pele humana. Para isso, será usando modelos de deep learning com arquitetura CNN e Densenet. \n",
    "\n",
    "Dicionário dos dados: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T\n",
    "\n",
    "Fonte dos dados: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee5e9a",
   "metadata": {},
   "source": [
    "## 1. Instalando e carregando pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a7276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A versão da linguagem Python utilizada neste Jupyter Notebook é:  3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da linguagem Python\n",
    "from platform import python_version\n",
    "print('A versão da linguagem Python utilizada neste Jupyter Notebook é: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469e114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala Pytorch\n",
    "!pip install -q torch==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb635159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala Torchvision\n",
    "!pip install -q torchvision==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fab032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala Lightning\n",
    "!pip install -q pytorch-lightning==1.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11575211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes/funções\n",
    "\n",
    "# Manipulação das imagens\n",
    "import os # Manipula o Sistema Operacional\n",
    "import cv2 # Converte imagens em dados\n",
    "import itertools # Iteração dos dados\n",
    "from tqdm import tqdm # Barra de progressão\n",
    "from glob import glob # Manipulação de imagens\n",
    "from PIL import Image # Manipulação de imagens\n",
    "\n",
    "# Manipulação e visualização dos dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Pacotes para o relatório de hardware\n",
    "import gc\n",
    "import types\n",
    "import pkg_resources\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Seend para reprodução dos resultados DSA\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be830fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Projeto 5 - IA para Análise de Imagens na Pele\n",
      "\n",
      "pytorch_lightning: 1.8.3\n",
      "torchvision      : 0.14.0\n",
      "matplotlib       : 3.5.2\n",
      "pandas           : 1.4.4\n",
      "PIL              : 9.2.0\n",
      "torch            : 1.13.0\n",
      "cv2              : 4.7.0\n",
      "numpy            : 1.21.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Projeto 5 - IA para Análise de Imagens na Pele\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab307ca",
   "metadata": {},
   "source": [
    "## 2. Verificando o Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e57941d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Visão Geral do Ambiente---------------------------------------\n",
      "\n",
      "Device: cpu\n",
      "Pasta de Dados:  dados\n",
      "Versões dos Pacotes Requeridos:  [('Pillow', '9.2.0'), ('tqdm', '4.64.1'), ('matplotlib', '3.5.2'), ('numpy', '1.21.5'), ('torch', '1.13.0'), ('pandas', '1.4.4'), ('torchvision', '0.14.0')]\n",
      "Dispositivo Que Será Usado Para Treinar o Modelo:  cpu\n",
      "CUDA Está Disponível?  False\n",
      "Versão do PyTorch:  1.13.0+cpu\n",
      "Versão do Lightning:  1.8.3\n",
      "\n",
      "------------------Se NVIDIA-SMI não for encontrado, então CUDA não está disponível------------------\n",
      "\n",
      "\n",
      "Limpando a Memória da GPU (se disponível):  None\n",
      "\n",
      "Modelo da GPU:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------Fim da Checagem-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# Relatório completo\n",
    "\n",
    "# Verificando o dispositivo\n",
    "processing_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Verificando se GPU pode ser usada (isso depende da plataforma CUDA estar instalada)\n",
    "torch_aval = torch.cuda.is_available()\n",
    "\n",
    "# Labels para o relatório de verificação\n",
    "lable_1 = 'Visão Geral do Ambiente'\n",
    "lable_2 = 'Se NVIDIA-SMI não for encontrado, então CUDA não está disponível'\n",
    "lable_3 = 'Fim da Checagem'\n",
    "\n",
    "# Função para verificar o que está importado nesta sessão\n",
    "def get_imports():\n",
    "\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):            \n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        poorly_named_packages = {\"PIL\": \"Pillow\", \"sklearn\": \"scikit-learn\"}\n",
    "\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "# Imports nesta sessão\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# Loop para verificar os requerimentos\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "        \n",
    "# Pasta com os dados (quando necessário)\n",
    "pasta_dados = r'dados'\n",
    "\n",
    "print(f'{lable_1:-^100}')\n",
    "print()\n",
    "print(f\"Device:\", processing_device)\n",
    "print(f\"Pasta de Dados: \", pasta_dados)\n",
    "print(f\"Versões dos Pacotes Requeridos: \", requirements)\n",
    "print(f\"Dispositivo Que Será Usado Para Treinar o Modelo: \", processing_device)\n",
    "print(f\"CUDA Está Disponível? \", torch_aval)\n",
    "print(\"Versão do PyTorch: \", torch.__version__)\n",
    "print(\"Versão do Lightning: \", pl.__version__)\n",
    "print()\n",
    "print(f'{lable_2:-^100}\\n')\n",
    "!nvidia-smi\n",
    "gc.collect()\n",
    "print()\n",
    "print(f\"Limpando a Memória da GPU (se disponível): \", torch.cuda.empty_cache())\n",
    "print(\"\\nModelo da GPU:\")\n",
    "# Modelo da GPU usada\n",
    "!nvidia-smi --query-gpu=name --format=csv,noheader\n",
    "print(f'\\n{lable_3:-^100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470f578",
   "metadata": {},
   "source": [
    "## 3. Interpretação dos metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4c5c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do arquivo de metadados\n",
    "df_inicial = pd.read_csv(os.path.join('dados', 'HAM10000_metadata.csv'))\n",
    "\n",
    "# Visualiza o registro\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56ef502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para as imagens\n",
    "caminho_imagens = glob(os.path.join('dados','*','*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413d4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dicionário com id da imagem e caminho do arquivo no disco\n",
    "dict_imagens = {os.path.splitext(os.path.basename(x))[0]: x for x in caminho_imagens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c2a2a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ISIC_0024306': 'dados\\\\HAM10000_images_part_1\\\\ISIC_0024306.jpg',\n",
       " 'ISIC_0024307': 'dados\\\\HAM10000_images_part_1\\\\ISIC_0024307.jpg',\n",
       " 'ISIC_0024308': 'dados\\\\HAM10000_images_part_1\\\\ISIC_0024308.jpg',\n",
       " 'ISIC_0024309': 'dados\\\\HAM10000_images_part_1\\\\ISIC_0024309.jpg',\n",
       " 'ISIC_0024310': 'dados\\\\HAM10000_images_part_1\\\\ISIC_0024310.jpg'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo 5 registros do dicionário\n",
    "dict(itertools.islice(dict_imagens.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb1da766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona o path ao df_inicial\n",
    "df_inicial['path'] = df_inicial['image_id'].map(dict_imagens.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f60a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0027419.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>dados\\HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                            path  \n",
       "0  dados\\HAM10000_images_part_1\\ISIC_0027419.jpg  \n",
       "1  dados\\HAM10000_images_part_1\\ISIC_0025030.jpg  \n",
       "2  dados\\HAM10000_images_part_1\\ISIC_0026769.jpg  \n",
       "3  dados\\HAM10000_images_part_1\\ISIC_0025661.jpg  \n",
       "4  dados\\HAM10000_images_part_2\\ISIC_0031633.jpg  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o dataset\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c96872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de lesões que serão analisadas de acordo com o dicionário de dados\n",
    "tipo_lesao_dict = {'nv': 'Melanocytic nevi',\n",
    "                   'mel': 'dermatofibroma',\n",
    "                   'bkl': 'Benign keratosis-like',\n",
    "                   'bcc': 'Basal cell carcinoma',\n",
    "                   'akiec': 'Actinic keratoses',\n",
    "                   'vasc': 'Vascular lesions',\n",
    "                   'df': 'Dermatofibroma'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf33a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair o tipo de lesão\n",
    "df_inicial['tipo_lesao'] = df_inicial['dx'].map(tipo_lesao_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce2b882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>tipo_lesao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0027419.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>dados\\HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                            path             tipo_lesao  \n",
       "0  dados\\HAM10000_images_part_1\\ISIC_0027419.jpg  Benign keratosis-like  \n",
       "1  dados\\HAM10000_images_part_1\\ISIC_0025030.jpg  Benign keratosis-like  \n",
       "2  dados\\HAM10000_images_part_1\\ISIC_0026769.jpg  Benign keratosis-like  \n",
       "3  dados\\HAM10000_images_part_1\\ISIC_0025661.jpg  Benign keratosis-like  \n",
       "4  dados\\HAM10000_images_part_2\\ISIC_0031633.jpg  Benign keratosis-like  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o dataset\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce11a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a variável categórica em sua representação numérica\n",
    "df_inicial['tipo_lesao_idx'] = pd.Categorical(df_inicial['tipo_lesao']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97c3fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>tipo_lesao</th>\n",
       "      <th>tipo_lesao_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0027419.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>dados\\HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>dados\\HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "      <td>Benign keratosis-like</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                            path             tipo_lesao  \\\n",
       "0  dados\\HAM10000_images_part_1\\ISIC_0027419.jpg  Benign keratosis-like   \n",
       "1  dados\\HAM10000_images_part_1\\ISIC_0025030.jpg  Benign keratosis-like   \n",
       "2  dados\\HAM10000_images_part_1\\ISIC_0026769.jpg  Benign keratosis-like   \n",
       "3  dados\\HAM10000_images_part_1\\ISIC_0025661.jpg  Benign keratosis-like   \n",
       "4  dados\\HAM10000_images_part_2\\ISIC_0031633.jpg  Benign keratosis-like   \n",
       "\n",
       "   tipo_lesao_idx  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o dataset\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34f973",
   "metadata": {},
   "source": [
    "## 4. Pré-Processamento dos dados  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9104e53",
   "metadata": {},
   "source": [
    "### 4.1 Extração da média e desvio padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdecd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para cálculo de média e desvio\n",
    "def func_calcula_img_mean_std(image_paths):\n",
    "\n",
    "    # Define altura e largura que usaremos nas imagens\n",
    "    # Densenet espera as imagens nesta dimensão\n",
    "    img_h, img_w = 224, 224\n",
    "    \n",
    "    # Listas de controle\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    # Loop de leitura e resize das imagens\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    # Stack de imagens\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    # Normalização\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    # Loop de cálculo da média e desvio\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  \n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    # BGR --> RGB\n",
    "    means.reverse()  \n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    \n",
    "    return means, stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1768d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10015/10015 [01:48<00:00, 91.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3, 10015)\n",
      "normMean = [0.7630331, 0.5456457, 0.5700467]\n",
      "normStd = [0.1409281, 0.15261227, 0.16997086]\n"
     ]
    }
   ],
   "source": [
    "# Retorna a média e o desvio padrão de cada canal RGB\n",
    "norm_mean, norm_std = func_calcula_img_mean_std(caminho_imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f676d66",
   "metadata": {},
   "source": [
    "### 4.2 Preparação para o dataset de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6555cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>tipo_lesao</th>\n",
       "      <th>tipo_lesao_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesion_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HAM_0000000</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000002</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  dx  dx_type  age  sex  localization  path  tipo_lesao  \\\n",
       "lesion_id                                                                      \n",
       "HAM_0000000         2   2        2    2    2             2     2           2   \n",
       "HAM_0000001         1   1        1    1    1             1     1           1   \n",
       "HAM_0000002         3   3        3    3    3             3     3           3   \n",
       "HAM_0000003         1   1        1    1    1             1     1           1   \n",
       "HAM_0000004         1   1        1    1    1             1     1           1   \n",
       "\n",
       "             tipo_lesao_idx  \n",
       "lesion_id                    \n",
       "HAM_0000000               2  \n",
       "HAM_0000001               1  \n",
       "HAM_0000002               3  \n",
       "HAM_0000003               1  \n",
       "HAM_0000004               1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica o número de imagens associadas ao lesion_id\n",
    "df_temp = df_inicial.groupby('lesion_id').count()\n",
    "\n",
    "# Visualiza o dataset\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b07db018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora filtramos lesion_ids que possuem apenas uma imagem associada\n",
    "df_temp = df_temp[df_temp['image_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5be0b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_temp.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9582ab1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>tipo_lesao</th>\n",
       "      <th>tipo_lesao_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  image_id  dx  dx_type  age  sex  localization  path  \\\n",
       "0  HAM_0000001         1   1        1    1    1             1     1   \n",
       "1  HAM_0000003         1   1        1    1    1             1     1   \n",
       "2  HAM_0000004         1   1        1    1    1             1     1   \n",
       "3  HAM_0000007         1   1        1    1    1             1     1   \n",
       "4  HAM_0000008         1   1        1    1    1             1     1   \n",
       "\n",
       "   tipo_lesao  tipo_lesao_idx  \n",
       "0           1               1  \n",
       "1           1               1  \n",
       "2           1               1  \n",
       "3           1               1  \n",
       "4           1               1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o dataset\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db325bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para identificar lesion_ids que possuem imagens duplicadas e aqueles que possuem apenas uma imagem\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_temp['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce42756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova coluna que seja uma cópia da coluna lesion_id\n",
    "df_inicial['duplicates'] = df_inicial['lesion_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea097f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a esta nova coluna\n",
    "df_inicial['duplicates'] = df_inicial['duplicates'].apply(get_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08cdfc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unduplicated    5514\n",
       "duplicated      4501\n",
       "Name: duplicates, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contagem dos valores duplicados\n",
    "df_inicial['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad94eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro das imagens que não têm duplicatas\n",
    "df_temp = df_inicial[df_inicial['duplicates'] == 'unduplicated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "137ed755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y\n",
    "y = df_temp['tipo_lesao_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "501b727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dataset de validação sem duplicatas\n",
    "_, df_val = train_test_split(df_temp, test_size = 0.2, random_state = 101, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fbcdad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 11)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o shape do dataset\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "271f6e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    883\n",
       "2     88\n",
       "6     46\n",
       "1     35\n",
       "0     30\n",
       "5     13\n",
       "3      8\n",
       "Name: tipo_lesao_idx, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica a contagem dos itens\n",
    "df_val['tipo_lesao_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416000ef",
   "metadata": {},
   "source": [
    "### 4.3 Separação das amostras de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "febe587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função identifica se uma imagem faz parte do conjunto train ou val\n",
    "def get_val_rows(x):\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb3c64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica treino ou validação\n",
    "df_inicial['train_or_val'] = df_inicial['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b59d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a esta nova coluna\n",
    "df_inicial['train_or_val'] = df_inicial['train_or_val'].apply(get_val_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2eb9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra as linhas de treino\n",
    "df_treino = df_inicial[df_inicial['train_or_val'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c872b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de treino:  8912\n",
      "Dataset de validação:  1103\n"
     ]
    }
   ],
   "source": [
    "# Verifica o número de registros\n",
    "print('Dataset de treino: ', len(df_treino))\n",
    "print('Dataset de validação: ', len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcbad55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5822\n",
       "6    1067\n",
       "2    1011\n",
       "1     479\n",
       "0     297\n",
       "5     129\n",
       "3     107\n",
       "Name: tipo_lesao_idx, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de itens por classe\n",
    "# Dataset desbalanceado\n",
    "df_treino['tipo_lesao_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7640f50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi         883\n",
       "Benign keratosis-like     88\n",
       "dermatofibroma            46\n",
       "Basal cell carcinoma      35\n",
       "Actinic keratoses         30\n",
       "Vascular lesions          13\n",
       "Dermatofibroma             8\n",
       "Name: tipo_lesao, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de itens por classe\n",
    "df_val['tipo_lesao'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cf50c",
   "metadata": {},
   "source": [
    "### 4.4 Dataset Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4547947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de dataset augmentation a ser usada em cada classe\n",
    "# É determinada de forma manual testando o balancemento no final\n",
    "data_aug_rate = [15,10,5,50,0,40,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d51d79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para o dataset augmentation\n",
    "for i in range(7):\n",
    "    \n",
    "    if data_aug_rate[i]:\n",
    "        \n",
    "        # Equaliza a proporção de imagens por classe nos dados de treino\n",
    "        # Geramos novas imagens multiplicando as imagens existentes pela taxa definida na lista de taxas\n",
    "        df_treino = df_treino.append([df_treino.loc[df_treino['tipo_lesao_idx'] == i,:]] * (data_aug_rate[i] - 1), \n",
    "                                     ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cef7c091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi         5822\n",
       "Dermatofibroma           5350\n",
       "dermatofibroma           5335\n",
       "Vascular lesions         5160\n",
       "Benign keratosis-like    5055\n",
       "Basal cell carcinoma     4790\n",
       "Actinic keratoses        4455\n",
       "Name: tipo_lesao, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza o dataset de treino\n",
    "df_treino['tipo_lesao'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97477983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_treino = df_treino.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e3065e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35967, 13)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape do dataset de treino\n",
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498148cf",
   "metadata": {},
   "source": [
    "### 4.5 Preparação das amostras de treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "666db67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados\n",
    "df_val, df_teste = train_test_split(df_val, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cba1783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_val = df_val.reset_index()\n",
    "df_teste = df_teste.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b47f9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados de treino:  (35967, 13)\n",
      "Shape dos dados de validação:  (551, 12)\n",
      "Shape dos dados de teste:  (552, 12)\n"
     ]
    }
   ],
   "source": [
    "# Shape dos dados\n",
    "\n",
    "print('Shape dos dados de treino: ', df_treino.shape)\n",
    "print('Shape dos dados de validação: ', df_val.shape)\n",
    "print('Shape dos dados de teste: ', df_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bd48b",
   "metadata": {},
   "source": [
    "### 4.6 Transformação das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cdab27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho das imagens de entrada\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2520a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações das imagens de treino\n",
    "transform_treino = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness = 0.1, contrast = 0.1, hue = 0.1),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48c77621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações das imagens de validação\n",
    "transform_val = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc5eaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define um organizador de dados\n",
    "class OrganizaDados(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['tipo_lesao_idx'][index]))\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "            \n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4882f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organiza e transforma os dados de treino\n",
    "set_treino = OrganizaDados(df_treino, transform = transform_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "320dfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organiza e transforma os dados de validação\n",
    "set_val = OrganizaDados(df_val, transform = transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd19f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organiza e transforma os dados de teste\n",
    "set_teste = OrganizaDados(df_teste, transform = transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3f3cf",
   "metadata": {},
   "source": [
    "### 4.7 Criação dos DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b118cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de treino\n",
    "loader_treino = DataLoader(set_treino, batch_size = 32, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77f63f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de validação\n",
    "loader_val = DataLoader(set_val, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77a5be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de teste\n",
    "loader_teste = DataLoader(set_teste, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0684f9",
   "metadata": {},
   "source": [
    "## 5. Modelagem - Arquitetura Densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32ed7e",
   "metadata": {},
   "source": [
    "A DenseNet, ou Rede Densa Conectada, é uma arquitetura de rede neural convolucional (CNN) proposta por Gao Huang, Zhuang Liu, Laurens van der Maaten e Kilian Q. Weinberger em 2016. \n",
    "\n",
    "A ideia principal por trás da DenseNet é promover a conexão direta entre camadas não adjacentes, facilitando o fluxo de informações e gradientes ao longo da rede. Essa arquitetura é especialmente eficiente no que diz respeito à utilização de recursos e melhora a qualidade das representações aprendidas.\n",
    "\n",
    "link: https://pytorch.org/vision/main/models/generated/torchvision.models.densenet121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a776c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de classes, quantidade de lesões na pele\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac519167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga do modelo pré-treinado com todos os pesos\n",
    "modelo_densenet = models.densenet121(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42be4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de atributos de entrada\n",
    "num_ftrs = modelo_densenet.classifier.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3d31f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camada linear final para prever a probabilidade das 7 classes\n",
    "modelo_densenet.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5676dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para definir o uso do modelo pré-treinado\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f45ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False porque o modelo terá atualização com os pesos\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50efa70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy da função\n",
    "set_parameter_requires_grad(modelo_densenet, feature_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce5126df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o device\n",
    "device = processing_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c82218af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloca o modelo no device\n",
    "modelo = modelo_densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47dd42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia o otimizador Adam\n",
    "optimizer = optim.Adam(modelo.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6830fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o cross entropy loss porque temos um problema multiclasse\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c34818f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  (fc): Linear(in_features=1024, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Visualiza a arquitetura Densenet\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a4383",
   "metadata": {},
   "source": [
    "## 6. Treinamento do Modelo Densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0dd7b",
   "metadata": {},
   "source": [
    "### 6.1 Funções para o loop de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbe16e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o erro em treino e validação durante o treinamento\n",
    "class CalculaMetricas(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2cf17369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para erro e acurácia em treino\n",
    "total_loss_train, total_acc_train = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4594a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treino do modelo\n",
    "def treina_modelo(treino_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # Coloca o modelo em modo de treino\n",
    "    model.train()\n",
    "    \n",
    "    # Inicializa objetos de cálculo de métricas\n",
    "    train_loss = CalculaMetricas()\n",
    "    train_acc = CalculaMetricas()\n",
    "    \n",
    "    # Iteração\n",
    "    curr_iter = (epoch - 1) * len(treino_loader)\n",
    "    \n",
    "    # Loop de treino\n",
    "    for i, data in enumerate(treino_loader):\n",
    "        \n",
    "        # Extra os dados\n",
    "        images, labels = data\n",
    "        \n",
    "        # Tamanho da imagem\n",
    "        N = images.size(0)\n",
    "        \n",
    "        # Coloca imagens e labels no device\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        # Zera os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Previsão do modelo\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Erro do modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Obtem a previsão de maior probabilidade\n",
    "        prediction = outputs.max(1, keepdim = True)[1]\n",
    "        \n",
    "        # Atualiza as métricas\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        \n",
    "        # Iteração\n",
    "        curr_iter += 1\n",
    "        \n",
    "        # Print e update das métricas\n",
    "        # A condição *** and curr_iter < 1000 *** pode ser removida se você quiser treinar com o dataset completo\n",
    "        if (i + 1) % 100 == 0 and curr_iter < 100:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (epoch, \n",
    "                                                                                       i + 1, \n",
    "                                                                                       len(treino_loader), \n",
    "                                                                                       train_loss.avg, \n",
    "                                                                                       train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "           \n",
    "    # Salva o modelo em disco\n",
    "    torch.save(model, 'modelos/modelo_projeto5.pth')\n",
    "\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbc8d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para erro e acurácia em validação\n",
    "total_loss_val, total_acc_val = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42f0a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para validação\n",
    "def valida_modelo(val_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # Coloca o modelo em modo de validação\n",
    "    model.eval()\n",
    "    \n",
    "    # Inicializa objetos de cálculo de métricas\n",
    "    val_loss = CalculaMetricas()\n",
    "    val_acc = CalculaMetricas()\n",
    "    \n",
    "    # Validação\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            \n",
    "            images, labels = data\n",
    "            \n",
    "            N = images.size(0)\n",
    "            \n",
    "            images = Variable(images).to(device)\n",
    "            \n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            \n",
    "            prediction = outputs.max(1, keepdim = True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf8d64",
   "metadata": {},
   "source": [
    "### 6.2 Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c96290d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "epoch_num = 10\n",
    "best_val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd471d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    \n",
    "    # Execute o loop de treino\n",
    "    loss_train, acc_train = treina_modelo(loader_treino, modelo, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Executa o loop de validação\n",
    "    loss_val, acc_val = valida_modelo(loader_val, modelo, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Calcula as métricas\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    \n",
    "    # Verifica a acurácia em validação\n",
    "    if acc_val > best_val_acc:\n",
    "        \n",
    "        best_val_acc = acc_val\n",
    "        \n",
    "        print('*****************************************************')\n",
    "        print('Melhor Resultado: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f697c",
   "metadata": {},
   "source": [
    "## 7. Avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d89eeb",
   "metadata": {},
   "source": [
    "No primeiro gráfico, as curvas precisam cruzar e naturalmente a curva de validação irá sobrepor a de erro. No gráfico abaixo, vemos uma tendência de aumento em acurácia e redução do erro do modelo conforme o número de épocas aumenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd676c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(num = 2)\n",
    "fig1 = fig.add_subplot(2,1,1)\n",
    "fig2 = fig.add_subplot(2,1,2)\n",
    "fig1.plot(total_loss_train, label = 'Erro em Treino')\n",
    "fig1.plot(total_acc_train, label = 'Acurácia em Treino')\n",
    "fig2.plot(total_loss_val, label = 'Erro em Validação')\n",
    "fig2.plot(total_acc_val, label = 'Acurácia em Validação')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11188603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo do disco\n",
    "modelo_final = torch.load('modelos/modelo_projeto5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo com dados de teste\n",
    "modelo_final.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(loader_teste):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = modelo(images)\n",
    "        prediction = outputs.max(1, keepdim = True)[1]\n",
    "        y_label.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783cbcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot da confusion_matrix\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix',\n",
    "                          cmap = plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Label Real')\n",
    "    plt.xlabel('Label Previsto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_label, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ea10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da confusion matrix\n",
    "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da01da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o relatório de classificação\n",
    "report = classification_report(y_label, y_predict, target_names = plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8f23d",
   "metadata": {},
   "source": [
    "No relatório, vemos que a classe \"mel\" teve um desempenho negativo em comparação com as demais, com diferentes taxas para precision, recall e f1-score. Isso ocorreu porque essa classe apresenta o menor número de itens no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a3ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de erros por classe\n",
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis = 1)\n",
    "plt.bar(np.arange(7),label_frac_error)\n",
    "plt.xlabel('Label Real')\n",
    "plt.ylabel('Classificação Incorreta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
