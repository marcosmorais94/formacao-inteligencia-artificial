{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8feaeef3",
   "metadata": {},
   "source": [
    "# Projeto Análise de Qualidade de Alimentos em Plantações Agrícola com IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c913886f",
   "metadata": {},
   "source": [
    "O objetivo é fazer o fine-tuningem um modelo Vision Transformer Pré-treinado  e  ajustá-lo  ao  nosso  próprio  caso  de  uso, a  fim  de  classificar  e  prever  a  qualidade  de alimentos  em  plantações  agrícolas. \n",
    "\n",
    "Com base em uma imagem de folha, o  objetivo desta tarefa é prever o tipo de doença (Mancha Angular e Ferrugem do Feijão), se houver.Os termos em inglês são Angular Leaf Spot eBean Rust.\n",
    "\n",
    "Fonte dos dados: https://huggingface.co/datasets/beans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff84603",
   "metadata": {},
   "source": [
    "## 1. Instalando e carregando os pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4cbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51966159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocultas avisos do Tensorflow\n",
    "%env TF_CPP_MIN_LOG_LEVEL=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala Torch\n",
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea033f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala Transformers\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala datasets\n",
    "!pip install -q datasets==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala accelerate\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import accelerate\n",
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Projeto Análise Imagens Agrícolas com IA\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ec253",
   "metadata": {},
   "source": [
    "## 2. Aplicando o Fine-Tunning ao Modelo\n",
    "Pré-processamento para processar os dados do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db16bf",
   "metadata": {},
   "source": [
    "### 2.1 Carga do dataset no disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "dados = load_dataset('beans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a977bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os dados\n",
    "print(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai os labels\n",
    "labels = dados['train'].features['labels']\n",
    "\n",
    "# Visualiza os dados\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0dc0a",
   "metadata": {},
   "source": [
    "### 2.2 Aplicando o ViT Feature Extractor para Processar as Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2cf40",
   "metadata": {},
   "source": [
    "O ViT Feature Extractor serve para transformar imagens de entrada em representações vetoriais de alto nível que podem ser usadas para uma variedade de tarefas além da classificação de imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580730ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repositório do ViT pré-treinado\n",
    "repo_id = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99798639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o ViTFeatureExtractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b228197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza o FeatureExtractor\n",
    "print(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o mapeamento de lotes de imagens e alpicação do ViTFeatureExtractor\n",
    "def transform(example_batch):\n",
    "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors = 'pt')\n",
    "    inputs['labels'] = example_batch['labels']\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara dos dados\n",
    "prepared_data = dados.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza um exemplo para conferir se a função está correta\n",
    "prepared_data['train'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para combinar as amostras\n",
    "# A função combina múltiplas amostras em um único lote para o processamento do Pytorch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    return{'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "          'labels': torch.tensor([x['labels'] for x in batch])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e7267f",
   "metadata": {},
   "source": [
    "## 3. Construção do Módulo de Treino do ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica do modelo\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04749391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da métrica\n",
    "def compute_metrics(prediction):\n",
    "    return metric.compute(predictions = np.armax(prediction.predictions, axis = 1),\n",
    "                         references = prediction.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia os labels\n",
    "labels = dados['train'].features['labels'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o modelo ViTForImageClassification indicandos os novos labels que serão usados\n",
    "modelo = ViTForImageClassification.from_pretrained(repo_id,\n",
    "                                                  num_labels = len(labels),\n",
    "                                                  id2label = {str(i):c for i, c in enumerate(labels)},\n",
    "                                                  label2id = {c:str(i) for i, c in enumerate(labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8b7ef",
   "metadata": {},
   "source": [
    "Esta mensagem acima está dizendo que você está inicializando um modelo ViTForImageClassification (um modelo de classificação de imagem Vision Transformer) a partir de um modelo pré-treinado (google/vit-base-patch16-224-in21k). No entanto, nem todos os pesos do modelo pré-treinado estão sendo usados na inicialização e alguns pesos do modelo ViTForImageClassification estão sendo inicializados do zero.\n",
    "\n",
    "Há dois pontos principais aqui:\n",
    "\n",
    "Alguns pesos do checkpoint do modelo ('pooler.dense.bias', 'pooler.dense.weight') não foram utilizados na inicialização do ViTForImageClassification. Isso pode ser esperado se você estiver inicializando o ViTForImageClassification a partir do checkpoint de um modelo treinado em outra tarefa ou com outra arquitetura. Se o modelo pré-treinado fosse exatamente idêntico à arquitetura que você está inicializando, você esperaria que todos os pesos fossem usados, e a mensagem informaria que algo está errado se isso não acontecesse.\n",
    "\n",
    "Alguns pesos do ViTForImageClassification ('classifier.bias', 'classifier.weight') não foram inicializados a partir do checkpoint do modelo e foram recém-inicializados. Isso significa que esses componentes específicos do modelo não receberam pesos do modelo pré-treinado e, em vez disso, foram inicializados, provavelmente com alguma forma de inicialização aleatória.\n",
    "\n",
    "A mensagem termina sugerindo que você provavelmente deve treinar (ou seja, fazer um \"fine-tuning\") este modelo em uma tarefa antes de usá-lo para predições e inferências. Isso ocorre porque, embora o modelo tenha sido parcialmente inicializado com pesos de um modelo pré-treinado, ele ainda tem alguns pesos que foram inicializados aleatoriamente e, portanto, precisam ser ajustados para a tarefa específica que você deseja resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argumentos de treino\n",
    "training_args = TrainingArguments(output_dir = \"resultados\",\n",
    "                                  evaluation_strategy = 'steps',\n",
    "                                  num_train_epochs = 4,\n",
    "                                  learning_rate = 2e-4,\n",
    "                                  remove_unused_columns = False,\n",
    "                                  load_best_model_at_end = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(model = modelo,\n",
    "                  args = training_args,\n",
    "                  data_collator = collate_fn,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  train_dataset = prepared_data['train'],\n",
    "                  eval_dataset = prepared_data['validation'],\n",
    "                  tokenizer = feature_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f777e7",
   "metadata": {},
   "source": [
    "## 4. Treino do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db09c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216da486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo em disco\n",
    "trainer.save_model('modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0997d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log das métricas\n",
    "trainer.log_metrics('train', train_results.metrics) env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva as métricas\n",
    "trainer.save_metrics('train', train_results.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3af0b5",
   "metadata": {},
   "source": [
    "## 5. Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo \n",
    "metrics = trainer.evaluate(prepared_data['validation'])\n",
    "trainer.log_metrics('eval', metrics)\n",
    "trainer.save_metrics('eval', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264556b",
   "metadata": {},
   "source": [
    "## 6. Deploy do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de uma imagem (experimente outras imagens)\n",
    "url = 'https://www.greenlife.co.ke/wp-content/uploads/2022/04/disease_bean_angular_leaf_spot.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a imagem\n",
    "image = Image.open(requests.get(url, stream = True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o extrator\n",
    "inputs = feature_extractor(images = image, return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da958991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloca a imagem no mesmo device do modelo\n",
    "inputs = {name: tensor.to(trainer.args.device) for name, tensor in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b050ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os inputs\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloca o modelo em modo de avaliação\n",
    "trainer.model.eval() \n",
    "\n",
    "# Desliga os gradientes para a inferência\n",
    "with torch.no_grad():  \n",
    "    outputs = trainer.model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai os logits\n",
    "logits = outputs.logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai o logit de maior valor para a imagem\n",
    "class_index = logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d12f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai o valor que desejamos do tensor\n",
    "valor = class_index.item()\n",
    "valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o mapeamento original (está na documentação do dataset bean)\n",
    "mapping = {\n",
    "  \"angular_leaf_spot\": 0,\n",
    "  \"bean_rust\": 1,\n",
    "  \"healthy\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um mapeamento reverso\n",
    "reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa o mapeamento reverso para obter o nome da classe\n",
    "class_name = reverse_mapping.get(valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A imagem foi classificada como:\", class_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
