{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Análise de Imagens com Inteligência Artificial</font>\n",
    "\n",
    "## <font color='blue'>Projeto 6</font>\n",
    "### <font color='blue'>Inteligência Artificial Para Análise de Imagens de Raio-X e Detecção de Doenças Pulmonares</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/P6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neurais Convolucionais são redes neurais usadas principalmente para classificar imagens, agrupar imagens por similaridade e realizar o reconhecimento de objetos nas cenas. \n",
    "\n",
    "Por exemplo, redes neurais convolucionais (ConvNets ou CNNs - Convolutional Neural Networks) são usadas para identificar rostos, indivíduos, placas de rua, tumores e muitos outros aspectos dos dados visuais.\n",
    "\n",
    "A eficácia das redes convolucionais no reconhecimento de imagens é uma das principais razões pelas quais o mundo despertou para a eficácia da aprendizagem profunda (Deep Learning). Em certo sentido, as CNNs são a razão pela qual a aprendizagem profunda é famosa. \n",
    "\n",
    "O sucesso de uma arquitetura convolucional profunda chamada AlexNet na competição ImageNet de 2012 foi o que começou a despertar a atenção do mundo. As CNNs estão impulsionando grandes avanços na Visão Computacional, que tem aplicações óbvias para carros autônomos, robótica, drones, segurança, diagnósticos médicos e tratamentos para deficientes visuais.\n",
    "\n",
    "As redes convolucionais também podem executar tarefas mais banais (e mais lucrativas), orientadas para os negócios, como o reconhecimento óptico de caracteres (OCR) para digitalizar texto e possibilitar o processamento em linguagem natural em documentos analógicos e manuscritos, onde as imagens são símbolos a serem transcritos.\n",
    "\n",
    "CNNs não se limitam ao reconhecimento de imagens, no entanto. Elas podem ser aplicadas diretamente à análise de texto. E elas são aplicadas ao som quando é representado visualmente como um espectrograma e a representar graficamente dados com redes convolucionais de grafos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagens São Tensores 4-D?\n",
    "\n",
    "As redes neurais convolucionais ingerem e processam imagens como tensores e os tensores são matrizes de números com dimensões adicionais.\n",
    "\n",
    "Eles podem ser difíceis de visualizar, então vamos abordá-los por analogia. Um escalar é apenas um número, como 7; um vetor é uma lista de números (por exemplo, [7,8,9]); e uma matriz é uma grade retangular de números que ocupa várias linhas e colunas como uma planilha. \n",
    "\n",
    "Geometricamente, se um escalar é um ponto de dimensão zero, um vetor é uma linha unidimensional, uma matriz é um plano bidimensional, uma pilha de matrizes é um cubo tridimensional e quando cada elemento dessas matrizes tem uma pilha de mapas de recursos anexados a ele, você entra na quarta dimensão. A imagem abaixo resumo o conceito:\n",
    "\n",
    "![title](imagens/tensores.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tensor abrange as dimensões além do plano 2-D. Você pode facilmente imaginar um tensor tridimensional, com a matriz de números organizados em um cubo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os tensores são formados por matrizes aninhadas em matrizes e esse aninhamento pode continuar infinitamente, respondendo por um número arbitrário de dimensões muito maiores do que o que podemos visualizar espacialmente. Um tensor 4-D simplesmente substituiria cada um dos escalares por uma matriz aninhada um nível mais profundo. As redes convolucionais lidam com tensores 4-D como o abaixo.\n",
    "\n",
    "![title](imagens/tensor4d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com algumas ferramentas, você verá o NDArray usado como sinônimo de tensor ou matriz multidimensional. A dimensionalidade de um tensor (1,2,3… n) é chamada de ordem; isto é, um tensor de quinta ordem teria cinco dimensões.\n",
    "\n",
    "A largura e a altura de uma imagem são facilmente entendidas. A profundidade é necessária devido ao modo como as cores são codificadas. A codificação Vermelho-Verde-Azul (RGB), por exemplo, produz uma imagem com três camadas de profundidade. Cada camada é chamada de \"canal\" e, por convolução, produz uma pilha de mapas de características (explicados abaixo), que existem na quarta dimensão. Recursos são apenas detalhes de imagens, como uma linha ou curva, das quais as redes convolucionais criam mapas.\n",
    "\n",
    "Então, em vez de pensar nas imagens como áreas bidimensionais, nas redes convolucionais elas são tratadas como volumes quadridimensionais. \n",
    "\n",
    "![title](imagens/tensor-slice.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Que é Convolução?\n",
    "\n",
    "![title](imagens/tensorconv.png)\n",
    "\n",
    "Para fins matemáticos, uma convolução é a medida integral de quanto duas funções se sobrepõem quando uma passa sobre a outra. Pense em uma convolução como uma maneira de misturar duas funções, multiplicando-as.\n",
    "\n",
    "![title](imagens/convgaus.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gif animado acima, a curva verde mostra a convolução das curvas azul e vermelha em função de t, a posição indicada pela linha verde vertical. A região cinza indica o produto g x f como uma função de t, então sua área como uma função de t é precisamente a convolução.\n",
    "\n",
    "Observe a curva alta e estreita do sino no meio do gráfico. A integral é a área sob essa curva. Próximo, há uma segunda curva de sino, mais curta e mais larga, flutuando lentamente do lado esquerdo do gráfico para a direita. O produto dessas duas funções se sobrepõe em cada ponto ao longo do eixo x é sua convolução. Então, de certa forma, as duas funções estão sendo “reunidas”.\n",
    "\n",
    "A próxima coisa a entender sobre redes convolucionais é que elas passam muitos filtros por uma única imagem, cada uma captando um sinal diferente. Em uma camada bastante inicial, você pode imaginá-los passando um filtro de linha horizontal, um filtro de linha vertical e um filtro de linha diagonal para criar um mapa das bordas da imagem.\n",
    "\n",
    "As redes convolucionais pegam esses filtros, fatias do espaço de destaque da imagem, e os mapeiam um por um; isto é, elas criam um mapa de cada local em que esse recurso ocorre. Ao aprender diferentes partes de um espaço de recursos, as redes convolucionais permitem uma engenharia de recursos facilmente escalável e robusta.\n",
    "\n",
    "Assim, as redes convolucionais realizam uma espécie de pesquisa. Imagine uma pequena lente de aumento deslizando da esquerda para a direita em uma imagem maior e recomeçando à esquerda quando chegar ao final de uma passagem (como as máquinas de escrever). Essa janela em movimento é capaz de reconhecer apenas uma coisa, digamos, uma pequena linha vertical. Três pixels escuros empilhados um sobre o outro. Ela move esse filtro de reconhecimento de linha vertical sobre os pixels reais da imagem, procurando correspondências.\n",
    "\n",
    "Cada vez que uma correspondência é encontrada, ela é mapeada para um espaço de recurso específico para esse elemento visual. Nesse espaço, a localização de cada correspondência de linha vertical é registrada. Uma rede convolucional realiza muitas e muitas buscas em uma única imagem - linhas horizontais, diagonais, tantas quanto houver elementos visuais a serem procurados.\n",
    "\n",
    "As redes convolucionais realizam mais operações de entrada do que apenas as próprias convoluções.\n",
    "\n",
    "Após uma camada convolucional, a entrada é passada através de uma transformação não linear, como tanh ou unidade linear retificada (ReLu), que \"esmagará\" os valores de entrada em um intervalo entre -1 e 1.\n",
    "\n",
    "Convolutional Network gif: https://mathworld.wolfram.com/Convolution.html\n",
    "\n",
    "![title](imagens/conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/convnetl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/feature_hierarchy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como Funcionam as Redes Neurais Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma Rede Neural Convolucional (ConvNet / CNN) é um algoritmo de Aprendizado Profundo que pode captar uma imagem de entrada, atribuir importância (pesos e vieses que são aprendidos no treinamento) a vários aspectos / objetos da imagem e ser capaz de diferenciar um do outro. \n",
    "\n",
    "O pré-processamento necessário em uma ConvNet é muito menor em comparação com outros algoritmos de classificação. Enquanto nos métodos primitivos os filtros são projetados manualmente, com treinamento suficiente, as ConvNets têm a capacidade de aprender esses filtros / características.\n",
    "\n",
    "A arquitetura de uma ConvNet é análoga à do padrão de conectividade dos neurônios no cérebro humano e foi inspirada pela organização do córtex visual. Neurônios individuais respondem a estímulos apenas em uma região restrita do campo visual, conhecida como Campo Receptivo. Uma coleção desses campos se sobrepõe para cobrir toda a área visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/cnn-arquitetura1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos e Mapas de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma imagem nada mais é do que uma matriz de valores de pixels, certo? Então, por que não achatar a imagem (por exemplo, matriz de imagem 3x3 em um vetor 9x1) e alimentá-la em uma rede neural? Sim, é isso que fazemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/convnet1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma ConvNet é capaz de capturar com sucesso as dependências espaciais e temporais em uma imagem através da aplicação de filtros relevantes. A arquitetura executa um melhor ajuste ao conjunto de dados da imagem devido à redução no número de parâmetros envolvidos e na reutilização de pesos. Em outras palavras, a rede pode ser treinada para entender melhor a sofisticação da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na figura abaixo, temos uma imagem RGB que foi separada por seus três planos de cores - vermelho, verde e azul. \n",
    "\n",
    "Existem vários desses espaços de cores nos quais as imagens são criadas - Escala de cinza, RGB, HSV, CMYK, etc.\n",
    "\n",
    "Você pode imaginar como as coisas seriam intensivamente computacionais quando as imagens atingissem dimensões, digamos 8K (7680 × 4320). O papel da ConvNet é reduzir as imagens para um formato mais fácil de processar, sem perder recursos essenciais para obter uma boa previsão. Isso é importante quando devemos projetar uma arquitetura que não seja apenas boa em aprender recursos, mas também seja escalável para conjuntos de dados maciços."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/convnet2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coonsidere uma imagem com dimensões = 5 (altura) x 5 (largura) x 1 (número de canais, por exemplo, RGB).\n",
    "\n",
    "Na demonstração abaixo, a seção verde se assemelha à nossa imagem de entrada 5x5x1. \n",
    "\n",
    "O elemento envolvido na execução da operação de convolução na primeira parte de uma Camada Convolucional é chamado Kernel / Filtro, K, representado na cor amarela. Selecionamos K como uma matriz 3x3x1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/convnet3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Kernel se desloca 9 vezes por causa do Comprimento da passada (stride) = 1, sempre executando uma operação de multiplicação de matrizes entre K e a parte P da imagem sobre a qual o kernel está passando.\n",
    "\n",
    "O filtro se move para a direita com um certo valor de passada até analisar a largura completa. Seguindo em frente, ele pula para o início (esquerda) da imagem com o mesmo valor de passada e repete o processo até que toda a imagem seja percorrida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/convnet4.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de imagens com vários canais (por exemplo, RGB), o Kernel tem a mesma profundidade que a da imagem de entrada. A multiplicação de matrizes é realizada entre as pilhas Kn e In ([K1, I1]; [K2, I2]; [K3, I3]) e todos os resultados são somados com o viés para nos fornecer uma saída de recurso de um canal compactado de uma profundidade.\n",
    "\n",
    "O objetivo da operação de convolução é extrair os recursos de alto nível, como bordas, da imagem de entrada. ConvNets não precisam ser limitados a apenas uma Camada Convolucional. Convencionalmente, a primeira ConvLayer é responsável por capturar os recursos de baixo nível, como bordas, cores, orientação de gradiente, etc. de imagens no conjunto de dados, semelhante a como faríamos.\n",
    "\n",
    "Existem dois tipos de resultados para a operação - um no qual o recurso envolvido é reduzido em dimensionalidade em comparação com a entrada e o outro no qual a dimensionalidade é aumentada ou permanece a mesma. Isso é feito aplicando Preenchimento (padding) válido no caso do primeiro, ou Mesmo Preenchimento (padding) no caso do último."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de uma CNN, a convolução é realizada nos dados de entrada com o uso de um filtro ou kernel (esses termos são usados de forma intercambiável) para produzir um Mapa de Recursos.\n",
    "\n",
    "Executamos uma convolução deslizando o filtro sobre a entrada. Em todos os locais, uma multiplicação de matrizes é realizada e soma o resultado no Mapa de Recursos.\n",
    "\n",
    "Na animação abaixo, você pode ver a operação de convolução. Você pode ver o filtro (o quadrado verde) deslizando sobre nossa entrada (o quadrado azul) e a soma da convolução entra no Mapa de Recursos (o quadrado vermelho).\n",
    "\n",
    "A área do nosso filtro também é chamada de campo receptivo, em homenagem às células dos neurônios! O tamanho desse filtro é 3x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/convnet5.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling/Downsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhante à camada convolucional, a camada Pooling é responsável por reduzir o tamanho espacial do recurso envolvido. \n",
    "Isso é para diminuir a potência computacional necessária para processar os dados através da redução de dimensionalidade. Além disso, é útil para extrair características dominantes que são invariantes rotacionais e posicionais, mantendo assim o processo de treinamento eficaz do modelo.\n",
    "\n",
    "Existem dois tipos de pool: Pool Máximo (Max Pooling) e Pool Médio (Average Pooling). Max Pooling retorna o valor máximo da parte da imagem coberta pelo Kernel. Por outro lado, o Average Pooling retorna a média de todos os valores da parte da imagem coberta pelo Kernel.\n",
    "\n",
    "O pool é uma maneira de capturar imagens grandes e reduzi-las enquanto preserva as informações mais importantes. A matemática por trás do pool é no nível básico. Consiste em passar uma pequena janela pela imagem e obter o valor máximo da janela em cada etapa. Na prática, uma janela de 2 ou 3 pixels em um lado e etapas de 2 pixels funcionam bem.\n",
    "\n",
    "Após o agrupamento, uma imagem possui cerca de um quarto dos pixels iniciados. Como mantém o valor máximo de cada janela, preserva os melhores ajustes de cada recurso dentro da janela. Isso significa que ele não se importa exatamente onde o recurso se encaixa, desde que se encaixe em algum lugar dentro da janela. O resultado disso é que as CNNs podem descobrir se um recurso está em uma imagem sem se preocupar com a localização. Isso ajuda a resolver o problema dos computadores serem hiperliterais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/cnn-arquitetura2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Max Pooling também funciona como um supressor de ruído. Ele descarta completamente as ativações ruidosas e também realiza a remoção do ruído junto com a redução da dimensionalidade. Por outro lado, o Average Pooling simplesmente realiza a redução da dimensionalidade como um mecanismo de supressão de ruído. Portanto, podemos dizer que o Max Pooling tem um desempenho muito melhor que o Average Pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A camada convolucional e a camada de pooling formam juntas a i-ésima camada de uma rede neural convolucional. \n",
    "\n",
    "Dependendo das complexidades nas imagens, o número de camadas pode ser aumentado para capturar detalhes de níveis ainda mais baixos, mas ao custo de mais poder computacional.\n",
    "\n",
    "Após seguir o processo acima, habilitamos o modelo com sucesso para entender os recursos. Continuando, vamos nivelar a saída final e alimentá-la com uma Rede Neural regular para fins de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por Que Usamos as Funções de Ativação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/cnn-arquitetura1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um participante pequeno, mas importante nesse processo, é a Função de Ativação, sendo a Unidade Linear Retificada ou ReLU a mais usada em Deep Learning atualmente. A matemática também é muito simples - onde quer que um número negativo ocorra, troque-o por um 0. Isso ajuda a CNN a manter-se matematicamente saudável, evitando que os valores aprendidos fiquem presos perto de 0 ou explodam em direção ao infinito. É a \"graxa de eixo\" das CNNs - não particularmente fascinante, mas sem ela as redes não vão muito longe.\n",
    "\n",
    "A função de ativação é um nó que é colocado no final ou entre as camadas. A função de ativação é a transformação não linear que fazemos sobre o sinal de entrada. Essa saída transformada é então enviada para a próxima camada de neurônios como entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/act-func.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos diferentes tipos de funções de ativação, sendo a Unidade Linear Retificada (ReLU) a mais comum em CNNs.\n",
    "\n",
    "Uma das maiores vantagens da ReLU em relação a outras funções de ativação é que ela não ativa todos os neurônios ao mesmo tempo. Na imagem da função ReLU acima, notamos que ela converte todas as entradas negativas em zero e o neurônio não é ativado. Isso a torna muito eficiente em termos computacionais, pois poucos neurônios são ativados por vez. Não satura na região positiva. Na prática, a ReLU converge seis vezes mais rápido que as funções de ativação tanh e sigmóide.\n",
    "\n",
    "Algumas desvantagens que ReLU apresenta é que ela está saturada na região negativa, significando que o gradiente nessa região é zero. Com o gradiente igual a zero, durante a retropropagação, todos os pesos não serão atualizados; para corrigir isso, podemos usar a Leaky ReLU. Além disso, as funções ReLU não são centralizadas em zero. Isso significa que, para chegar ao seu ponto ideal, ela precisará usar um caminho em zig-zag que pode ser mais longo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada Totalmente Conectada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta camada, os neurônios têm uma conexão completa com todas as ativações das camadas anteriores. Suas ativações podem, portanto, ser calculadas com uma multiplicação de matrizes seguida por um deslocamento de polarização. Esta é a última fase para uma rede CNN.\n",
    "\n",
    "A Rede Neural Convolucional é na verdade composta de camadas ocultas e camadas totalmente conectadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/fc.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionar uma camada totalmente conectada é uma maneira (geralmente) barata de aprender combinações dos recursos de alto nível, conforme representado pela saída da camada convolucional. \n",
    "\n",
    "Agora que convertemos nossa imagem de entrada em um formato adequado de vários níveis, achataremos a imagem em um vetor de coluna. A saída achatada é alimentada a uma rede neural feed-forward e o backpropagation é aplicado a todas as iterações do treinamento. Ao longo de uma série de épocas, o modelo é capaz de distinguir entre certos recursos de baixo nível e recursos dominantes nas imagens e classificá-los usando a técnica de Classificação Softmax. Na prática, essa etapa final é um modelo de Machine Learning para Classificação, que recebe como entrada os recursos aprendidos nas camadas convolução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ter ficado como muitas perguntas durante as aulas anteriores:\n",
    "\n",
    "- Como os filtros na primeira camada convolucional sabem procurar arestas e curvas? \n",
    "- Como a camada totalmente conectada sabe quais mapas de atributos devem ser usados? \n",
    "- Como os filtros em cada camada sabem quais valores devem ser usados? \n",
    "\n",
    "A maneira como o computador é capaz de ajustar seus valores (ou pesos) de filtro é através de um processo de treinamento chamado retropropagação ou Backpropagation.\n",
    "\n",
    "Antes de começarmos a retropropagação, precisamos primeiro dar um passo atrás e falar sobre o que uma rede neural precisa para funcionar. \n",
    "\n",
    "No momento em que todos nascemos, nossas mentes estavam frescas. Não sabíamos o que era um gato, cachorro ou pássaro. De maneira semelhante, antes do início do treinamento da CNN, os pesos ou valores do filtro são escolhidos de forma aleatória, pois ainda não sabemos quais são os melhores valores. Isso é o que a rede vai aprender. \n",
    "\n",
    "Os filtros não sabem procurar arestas e curvas. Os filtros nas camadas superiores não sabem procurar patas e bicos. \n",
    "\n",
    "No entanto, à medida que vamos para a escola, nossos pais e professores nos mostram fotos e imagens diferentes e nos dão um rótulo correspondente. Essa ideia de receber uma imagem e um rótulo é o processo de treinamento pelo qual as CNNs passam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/cnn_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, o treinamento da rede neural pode ser separado em 4 seções distintas: \n",
    "\n",
    "- Passagem para frente (feed-forward)\n",
    "- Função de perda (loss function) \n",
    "- Passagem para trás (backpropagation) \n",
    "- Atualização de peso\n",
    "\n",
    "Para começar, você pega uma imagem de treinamento que, como sabemos, é uma matriz de números de 32 x 32 x 3 e a passa por toda a rede. \n",
    "\n",
    "Em nosso primeiro exemplo de treinamento, como todos os pesos ou valores de filtro foram inicializados aleatoriamente, a saída provavelmente será algo como [.1 .1 .1 .1 .1 .1 .1 .1 .1 .1 .1], basicamente um saída que não dá preferência a nenhum número em particular. \n",
    "\n",
    "A rede, com seus pesos atuais, não é capaz de procurar esses recursos de baixo nível ou, portanto, não é capaz de chegar a uma conclusão razoável sobre qual poderia ser a classificação. \n",
    "\n",
    "Isso vai para a parte da função de perda da retropropagação. Lembre-se de que o que estamos usando agora são dados de treinamento. Esses dados têm uma imagem e um rótulo. Digamos, por exemplo, que a primeira imagem de treinamento inserida foi um 3. O rótulo da imagem seria [0 0 0 1 0 0 0 0 0 0 0]. Uma função de perda pode ser definida de várias maneiras diferentes, mas uma comum é MSE (erro quadrático médio), que é ½ vezes (previsto atualmente) ao quadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode imaginar, a perda será extremamente alta para as duas primeiras imagens de treinamento. Agora, vamos pensar sobre isso intuitivamente. Queremos chegar a um ponto em que o rótulo previsto (saída da ConvNet) seja o mesmo que o rótulo de treinamento (isso significa que nossa rede acertou sua previsão). Para chegar lá, queremos minimizar a quantidade de perdas (erros). Visualizando isso como apenas um problema de otimização no cálculo, queremos descobrir quais entradas (pesos no nosso caso) contribuíram mais diretamente para a perda (ou erro) da rede. E então atualizamos os pesos para a próxima passada. Repetimos esse processo dezenas, centenas ou milhares de vezes até que o aprendizado aconteça."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/back.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é o equivalente matemático de um dL/dW em que W são os pesos em uma camada específica. Agora, o que queremos fazer é realizar uma passagem reversa pela rede, que determina quais pesos contribuíram mais para a perda e encontrar maneiras de ajustá-los para que a perda diminua. Depois de calcularmos essa derivada, passamos para a última etapa, que é a atualização de peso. É aqui que pegamos todos os pesos dos filtros e os atualizamos para que eles mudem na direção oposta do gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/pesos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A taxa de aprendizado (learning rate) é um parâmetro escolhido pelo Cientista de Dados. Uma alta taxa de aprendizado significa que são tomadas medidas maiores nas atualizações de peso e, portanto, pode levar menos tempo para o modelo convergir para um conjunto ideal de pesos. No entanto, uma taxa de aprendizado muito alta pode resultar em saltos muito grandes e pouco precisos para atingir o ponto ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de passagem para frente, função de perda, passagem para trás e atualização de parâmetros (pesos) é uma iteração de treinamento. O programa repetirá esse processo para um número fixo de iterações para cada conjunto de imagens de treinamento (geralmente chamado de lote). Depois de concluir a atualização do parâmetro no último exemplo de treinamento, esperamos que a rede seja treinada o suficiente para que os pesos das camadas sejam ajustados corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura Final das Convnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/final.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referências:\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6108980/\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "cnnp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
